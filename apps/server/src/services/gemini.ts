import { GoogleGenerativeAI } from "@google/generative-ai";

export interface CodeSuggestion {
  file: string;
  line?: number;
  original?: string;
  suggested?: string;
  reason: string;
  severity: 'HIGH' | 'MEDIUM' | 'LOW';
  category: string;
}

interface FileAnalysis {
  filename: string;
  summary: string;
  issues: CodeSuggestion[];
  complexity: 'LOW' | 'MEDIUM' | 'HIGH';
  riskLevel: 'LOW' | 'MEDIUM' | 'HIGH';
  dependencies: string[];
}

interface CrossFileAnalysis {
  consistencyIssues: string[];
  dependencyConflicts: string[];
  architecturalConcerns: string[];
  integrationRisks: string[];
}

interface MultiPassAnalysisResult {
  // Pass 1: High-level overview
  overallSummary: string;
  impactAssessment: string;
  changeComplexity: 'LOW' | 'MEDIUM' | 'HIGH';
  
  // Pass 2: File-by-file analysis
  fileAnalyses: FileAnalysis[];
  
  // Pass 3: Cross-file analysis
  crossFileAnalysis: CrossFileAnalysis;
  
  // Pass 4: Final prioritization
  prioritizedIssues: CodeSuggestion[];
  riskAssessment: string;
  recommendedActions: string[];
  
  // Legacy compatibility
  summary: string;
  refactorSuggestions: string;
  potentialIssues: string;
  detailedAnalysis?: {
    overview: string;
    codeSuggestions: CodeSuggestion[];
    securityConcerns: string[];
    performanceImpact: string;
    testingRecommendations: string[];
    architecturalNotes: string[];
  };
}

interface AIAnalysisResult {
  summary: string;
  refactorSuggestions: string;
  potentialIssues: string;
  detailedAnalysis?: {
    overview: string;
    codeSuggestions: CodeSuggestion[];
    securityConcerns: string[];
    performanceImpact: string;
    testingRecommendations: string[];
    architecturalNotes: string[];
  };
  multiPassAnalysis?: MultiPassAnalysisResult;
}

export class GeminiService {
  private genAI: GoogleGenerativeAI;
  private model: any;
  private currentDiff?: string; // eslint-disable-line @typescript-eslint/no-explicit-any

  constructor(apiKey: string) {
    if (!apiKey) {
      throw new Error("Gemini API key must be provided");
    }
    
    this.genAI = new GoogleGenerativeAI(apiKey);
    // Use Gemini 2.5 Pro for more comprehensive analysis with improved reasoning
    this.model = this.genAI.getGenerativeModel({ 
      model: "gemini-2.5-pro",
      generationConfig: {
        temperature: 0.1, // Lower temperature for more consistent, focused analysis
        topK: 40,
        topP: 0.95,
        maxOutputTokens: 8192, // Increased for detailed analysis
      }
    });
  }

  async analyzePullRequest(
    prTitle: string,
    prDescription: string,
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>,
    enableMultiPass: boolean = false,
    enableStaticAnalysis: boolean = false,
    enhancedContext?: any
  ): Promise<AIAnalysisResult> {
    try {
      if (enableStaticAnalysis) {
        // Static analysis enhanced AI review
        return await this.runStaticEnhancedAnalysis(prTitle, prDescription, diff, changedFiles);
      } else if (enableMultiPass) {
        // Simple, focused code analysis for better recommendations
        const prompt = this.buildFocusedCodePrompt(prTitle, prDescription, diff, changedFiles, enhancedContext);
        
        const result = await this.model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();
        
        return this.parseCodeFocusedResponse(text, changedFiles, diff);
      } else {
        // Single-pass analysis (existing behavior)
        const prompt = this.buildAnalysisPrompt(prTitle, prDescription, diff, changedFiles);
        
        const result = await this.model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();
        
        return this.parseAIResponse(text);
      }
    } catch (error) {
      console.error("Error analyzing PR with Gemini:", error);
      throw new Error(`AI analysis failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  private async runStaticEnhancedAnalysis(
    prTitle: string,
    prDescription: string,
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>
  ): Promise<AIAnalysisResult> {
    // Import static analysis service
    const { getStaticAnalysisService } = await import('./static-analysis');
    const staticAnalysisService = getStaticAnalysisService();
    
    // Extract file contents from diff
    const fileContents = staticAnalysisService.extractFileContents(diff);
    
    // Run static analysis
    const staticResults = await staticAnalysisService.analyzeCode(fileContents);
    
    // Build enhanced prompt with static analysis context
    const prompt = this.buildStaticEnhancedPrompt(
      prTitle, 
      prDescription, 
      diff, 
      changedFiles, 
      staticResults
    );
    
    const result = await this.model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    // Parse with static analysis context
    const aiResult = this.parseAIResponse(text);
    
    // Enhance the result with static analysis data
    return {
      ...aiResult,
      detailedAnalysis: {
        ...aiResult.detailedAnalysis,
        overview: `${aiResult.detailedAnalysis?.overview || aiResult.summary} [Static Analysis: ${staticResults.summary.totalIssues} issues found by ${staticResults.summary.toolsRun.join(', ')}]`,
        codeSuggestions: [
          ...(aiResult.detailedAnalysis?.codeSuggestions || []),
          ...this.convertStaticIssuesToSuggestions(staticResults.issues, fileContents)
        ],
        securityConcerns: [
          ...(aiResult.detailedAnalysis?.securityConcerns || []),
          ...staticResults.issues
            .filter(issue => issue.category === 'security')
            .map(issue => `${issue.file}:${issue.line} - ${issue.message} (${issue.rule})`)
        ],
        performanceImpact: staticResults.issues.filter(issue => issue.category === 'performance').length > 0 
          ? `Performance concerns detected: ${staticResults.issues.filter(issue => issue.category === 'performance').length} issues found`
          : 'No performance issues detected',
        testingRecommendations: aiResult.detailedAnalysis?.testingRecommendations || [],
        architecturalNotes: aiResult.detailedAnalysis?.architecturalNotes || []
      }
    };
  }

  private buildStaticEnhancedPrompt(
    prTitle: string,
    prDescription: string,
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>,
    staticResults: any
  ): string {
    const fileSummary = changedFiles.map(file => 
      `- ${file.filename}: +${file.additions} -${file.deletions}`
    ).join('\n');

    const staticIssuesSummary = staticResults.issues.length > 0 
      ? `\nSTATIC ANALYSIS FINDINGS (${staticResults.issues.length} issues):\n${
          staticResults.issues.slice(0, 10).map((issue: any) => 
            `- ${issue.file}:${issue.line} [${issue.severity}] ${issue.message} (${issue.rule})`
          ).join('\n')
        }${staticResults.issues.length > 10 ? '\n... and more' : ''}`
      : '\nSTATIC ANALYSIS: No issues found';

    return `You are a senior software engineer. You have static analysis results to help guide your review.

PR: ${prTitle}
Files: ${fileSummary}${staticIssuesSummary}

Code Changes:
\`\`\`diff
${diff}
\`\`\`

The static analysis tools found ${staticResults.summary.totalIssues} issues. Use these findings to provide deeper insights.

Focus on:
1. **Validate Static Findings**: Confirm if static analysis issues are real problems
2. **Find Additional Issues**: Look for problems static analysis missed
3. **Provide Context**: Explain WHY issues matter and HOW to fix them
4. **Code Improvements**: Suggest better patterns and practices

Respond with ONLY valid JSON:
{
  "summary": "What this PR does",
  "refactorSuggestions": "Specific improvements with code examples",
  "potentialIssues": "Critical issues to address",
  "detailedAnalysis": {
    "overview": "Technical analysis including static analysis insights",
    "codeSuggestions": [
      {
        "file": "filename",
        "line": 42,
        "original": "problematic code",
        "suggested": "improved code",
        "reason": "why this improves the code",
        "severity": "HIGH|MEDIUM|LOW",
        "category": "Security|Performance|Logic|Style"
      }
    ],
    "securityConcerns": ["Security issues found"],
    "performanceImpact": "Performance analysis",
    "testingRecommendations": ["Testing suggestions"],
    "architecturalNotes": ["Architecture observations"]
  }
}`;
  }

  private convertStaticIssuesToSuggestions(issues: any[], fileContents?: Array<{ filename: string; content: string }>): any[] {
    return issues
      .filter(issue => issue.severity === 'error' || issue.severity === 'warning')
      .slice(0, 5) // Limit to top 5 static issues
      .map(issue => ({
        file: issue.file,
        line: issue.line,
        original: this.extractActualCodeFromFile(issue, fileContents, 'original'),
        suggested: this.extractActualCodeFromFile(issue, fileContents, 'suggested'),
        reason: `Static analysis (${issue.tool}) found: ${issue.message}. Rule: ${issue.rule}`,
        severity: issue.severity === 'error' ? 'HIGH' : 'MEDIUM',
        category: issue.category === 'security' ? 'Security' : 
                 issue.category === 'performance' ? 'Performance' : 'Logic'
      }));
  }

  private generateOriginalCodeFromIssue(issue: any): string {
    // Generate actual code examples based on common ESLint rules
    switch (issue.rule) {
      case 'no-unused-vars':
        return `const unusedVariable = 'value';\n// Variable is declared but never used`;
      case 'no-console':
        return `console.log('Debug message');`;
      case 'eqeqeq':
        return `if (value == null) {\n  // Using loose equality\n}`;
      case 'no-var':
        return `var oldStyleVariable = 'value';`;
      case 'prefer-const':
        return `let variable = 'value';\n// Variable is never reassigned`;
      case 'no-undef':
        return `undefinedVariable = 'value';\n// Variable is not defined`;
      case 'semi':
        return `const statement = 'missing semicolon'`;
      case 'quotes':
        return `const message = "inconsistent quotes";`;
      case 'indent':
        return `function example() {\nreturn 'incorrect indentation';\n}`;
      default:
        return `// Code with ${issue.rule} violation\n// Line ${issue.line}: ${issue.message}`;
    }
  }

  private generateSuggestedCodeFromIssue(issue: any): string {
    // Generate fixed code examples based on common ESLint rules
    switch (issue.rule) {
      case 'no-unused-vars':
        return `// Remove unused variable or use it:\nconst usedVariable = 'value';\nconsole.log(usedVariable);`;
      case 'no-console':
        return `// Use proper logging or remove:\n// console.log('Debug message');`;
      case 'eqeqeq':
        return `if (value === null) {\n  // Using strict equality\n}`;
      case 'no-var':
        return `const modernVariable = 'value';`;
      case 'prefer-const':
        return `const variable = 'value';\n// Use const for variables that are never reassigned`;
      case 'no-undef':
        return `const definedVariable = 'value';\n// Declare variable before use`;
      case 'semi':
        return `const statement = 'with semicolon';`;
      case 'quotes':
        return `const message = 'consistent quotes';`;
      case 'indent':
        return `function example() {\n  return 'correct indentation';\n}`;
      default:
        return `// Fixed code addressing ${issue.rule}\n// Resolved: ${issue.message}`;
    }
  }

  private extractOriginalCodeFromSuggestion(item: any, diff?: string): string {
    // Extract original code from AI suggestion, fallback to diff extraction
    if (item.originalCode) return item.originalCode;
    if (item.codeExample && item.codeExample.before) return item.codeExample.before;
    
    // Try to extract from diff if available
    if (diff && item.file && item.line) {
      const actualCode = this.extractCodeFromDiff(diff, item.file, item.line, 'original');
      if (actualCode) return actualCode;
    }
    
    // Generate example based on suggestion content
    return this.generateCodeExampleFromText(item.suggestion, 'original');
  }

  private extractSuggestedCodeFromSuggestion(item: any, diff?: string): string {
    // Extract suggested code from AI suggestion
    if (item.suggestedCode) return item.suggestedCode;
    if (item.codeExample && item.codeExample.after) return item.codeExample.after;
    if (item.suggestion && item.suggestion.includes('```')) {
      // Extract code blocks from suggestion text
      const codeMatch = item.suggestion.match(/```[\w]*\n([\s\S]*?)\n```/);
      if (codeMatch) return codeMatch[1];
    }
    
    // Try to extract and fix from diff if available
    if (diff && item.file && item.line) {
      const originalCode = this.extractCodeFromDiff(diff, item.file, item.line, 'original');
      if (originalCode) {
        // Apply intelligent fixes based on the suggestion content
        return this.applyIntelligentFix(originalCode, item.suggestion);
      }
    }
    
    return this.generateCodeExampleFromText(item.suggestion, 'suggested');
  }

  private extractOriginalCodeFromIssue(item: any): string {
    if (item.originalCode) return item.originalCode;
    if (item.codeExample && item.codeExample.before) return item.codeExample.before;
    
    return this.generateCodeExampleFromText(item.issue, 'original');
  }

  private extractSuggestedCodeFromIssue(item: any): string {
    if (item.suggestedCode) return item.suggestedCode;
    if (item.codeExample && item.codeExample.after) return item.codeExample.after;
    if (item.fix && item.fix.includes('```')) {
      const codeMatch = item.fix.match(/```[\w]*\n([\s\S]*?)\n```/);
      if (codeMatch) return codeMatch[1];
    }
    
    return this.generateCodeExampleFromText(item.issue, 'suggested');
  }

  private extractOriginalCodeFromBestPractice(item: any): string {
    if (item.originalCode) return item.originalCode;
    if (item.codeExample && item.codeExample.before) return item.codeExample.before;
    
    return this.generateCodeExampleFromText(item.suggestion, 'original');
  }

  private extractSuggestedCodeFromBestPractice(item: any): string {
    if (item.suggestedCode) return item.suggestedCode;
    if (item.codeExample && item.codeExample.after) return item.codeExample.after;
    if (item.suggestion && item.suggestion.includes('```')) {
      const codeMatch = item.suggestion.match(/```[\w]*\n([\s\S]*?)\n```/);
      if (codeMatch) return codeMatch[1];
    }
    
    return this.generateCodeExampleFromText(item.suggestion, 'suggested');
  }

  private extractActualCodeFromFile(issue: any, fileContents?: Array<{ filename: string; content: string }>, type: 'original' | 'suggested' = 'original'): string {
    if (!fileContents) {
      return this.generateCodeExampleFromText(issue.message || issue.rule || '', type);
    }

    // Find the file content
    const fileContent = fileContents.find(f => f.filename === issue.file);
    if (!fileContent) {
      return this.generateCodeExampleFromText(issue.message || issue.rule || '', type);
    }

    const lines = fileContent.content.split('\n');
    const lineNumber = issue.line || 1;
    
    // Extract context around the problematic line (3 lines before and after)
    const startLine = Math.max(0, lineNumber - 4);
    const endLine = Math.min(lines.length, lineNumber + 3);
    const contextLines = lines.slice(startLine, endLine);
    
    if (type === 'original') {
      // Return the actual problematic code with context
      return contextLines.join('\n').trim() || this.generateCodeExampleFromText(issue.message || issue.rule || '', type);
    } else {
      // Generate fixed version based on the rule
      return this.generateFixedCodeFromRule(issue, contextLines.join('\n').trim());
    }
  }

  private generateFixedCodeFromRule(issue: any, originalCode: string): string {
    if (!originalCode) {
      return this.generateCodeExampleFromText(issue.message || issue.rule || '', 'suggested');
    }

    // Apply specific fixes based on ESLint rules
    switch (issue.rule) {
      case 'no-unused-vars':
        // Remove or comment out unused variables
        return originalCode.replace(/const\s+(\w+)\s*=.*?;/g, '// Removed unused variable: $1');
      
      case 'no-console':
        // Comment out console statements
        return originalCode.replace(/console\.(log|warn|error|info)\(/g, '// console.$1(');
      
      case 'eqeqeq':
        // Replace == with ===
        return originalCode.replace(/\s==\s/g, ' === ').replace(/\s!=\s/g, ' !== ');
      
      case 'no-var':
        // Replace var with const/let
        return originalCode.replace(/var\s+/g, 'const ');
      
      case 'prefer-const':
        // Replace let with const for variables that aren't reassigned
        return originalCode.replace(/let\s+/g, 'const ');
      
      case 'semi':
        // Add missing semicolons
        return originalCode.replace(/([^;])\n/g, '$1;\n');
      
      case 'quotes':
        // Standardize quotes to single quotes
        return originalCode.replace(/"/g, "'");
      
      case 'indent':
        // Fix indentation (simple 2-space indentation)
        return originalCode.split('\n').map(line => {
          const trimmed = line.trim();
          if (!trimmed) return '';
          // Simple indentation logic
          const depth = (line.match(/^\s*/)?.[0].length || 0);
          const normalizedDepth = Math.floor(depth / 2) * 2;
          return ' '.repeat(normalizedDepth) + trimmed;
        }).join('\n');
      
      default:
        // For unknown rules, add a comment with the fix suggestion
        return `${originalCode}\n// TODO: ${issue.message}`;
    }
  }

  private extractCodeFromDiff(diff: string, filename: string, lineNumber: number, type: 'original' | 'suggested'): string | null {
    const diffLines = diff.split('\n');
    let currentFile = '';
    let currentLineNumber = 0;
    let inFileContent = false;
    
    for (let i = 0; i < diffLines.length; i++) {
      const line = diffLines[i];
      
      if (line.startsWith('diff --git')) {
        const match = line.match(/diff --git a\/(.+) b\/(.+)/);
        currentFile = match ? match[2] : '';
        inFileContent = false;
        currentLineNumber = 0;
      } else if (line.startsWith('@@') && currentFile === filename) {
        // Parse line numbers from hunk header
        const hunkMatch = line.match(/@@ -(\d+),?\d* \+(\d+),?\d* @@/);
        if (hunkMatch) {
          currentLineNumber = parseInt(hunkMatch[1]);
          inFileContent = true;
        }
      } else if (inFileContent && currentFile === filename) {
        if (line.startsWith(' ')) {
          // Context line
          currentLineNumber++;
          if (currentLineNumber === lineNumber) {
            // Extract context around this line
            return this.extractContextAroundLine(diffLines, i, 3);
          }
        } else if (line.startsWith('-')) {
          // Deleted line (original)
          if (type === 'original' && currentLineNumber === lineNumber) {
            return this.extractContextAroundLine(diffLines, i, 3);
          }
          currentLineNumber++;
        } else if (line.startsWith('+')) {
          // Added line (suggested)
          if (type === 'suggested' && currentLineNumber === lineNumber) {
            return this.extractContextAroundLine(diffLines, i, 3);
          }
          // Don't increment line number for added lines in original context
        }
      }
    }
    
    return null;
  }

  private extractContextAroundLine(diffLines: string[], centerIndex: number, contextSize: number): string {
    const start = Math.max(0, centerIndex - contextSize);
    const end = Math.min(diffLines.length, centerIndex + contextSize + 1);
    
    return diffLines.slice(start, end)
      .map(line => {
        // Remove diff prefixes for cleaner code display
        if (line.startsWith('+ ')) return line.substring(2);
        if (line.startsWith('- ')) return line.substring(2);
        if (line.startsWith('  ')) return line.substring(2);
        return line;
      })
      .filter(line => !line.startsWith('@@') && !line.startsWith('diff --git'))
      .join('\n')
      .trim();
  }

  private applyIntelligentFix(originalCode: string, suggestion: string): string {
    const lowerSuggestion = suggestion.toLowerCase();
    
    // Apply fixes based on suggestion content
    if (lowerSuggestion.includes('async') || lowerSuggestion.includes('await')) {
      return originalCode.replace(/function\s+(\w+)/g, 'async function $1')
                        .replace(/return\s+fetch\(/g, 'return await fetch(');
    }
    
    if (lowerSuggestion.includes('const') && lowerSuggestion.includes('let')) {
      return originalCode.replace(/let\s+/g, 'const ');
    }
    
    if (lowerSuggestion.includes('===') || lowerSuggestion.includes('strict equality')) {
      return originalCode.replace(/\s==\s/g, ' === ').replace(/\s!=\s/g, ' !== ');
    }
    
    if (lowerSuggestion.includes('semicolon')) {
      return originalCode.replace(/([^;])\n/g, '$1;\n');
    }
    
    if (lowerSuggestion.includes('error handling') || lowerSuggestion.includes('try-catch')) {
      return `try {\n${originalCode}\n} catch (error) {\n  console.error('Error:', error);\n  throw error;\n}`;
    }
    
    // If suggestion contains code blocks, extract and use them
    const codeMatch = suggestion.match(/```[\w]*\n([\s\S]*?)\n```/);
    if (codeMatch) {
      return codeMatch[1];
    }
    
    // Default: add suggestion as comment
    return `${originalCode}\n// Suggested improvement: ${suggestion.slice(0, 100)}...`;
  }

  private generateCodeExampleFromText(text: string, type: 'original' | 'suggested'): string {
    // Generate realistic code examples based on text content
    const lowerText = text.toLowerCase();
    
    if (lowerText.includes('function') || lowerText.includes('method')) {
      return type === 'original' 
        ? `function example() {\n  // Original implementation\n  return 'old way';\n}`
        : `function example() {\n  // Improved implementation\n  return 'better way';\n}`;
    }
    
    if (lowerText.includes('variable') || lowerText.includes('const') || lowerText.includes('let')) {
      return type === 'original'
        ? `let variable = 'original value';`
        : `const variable = 'improved value';`;
    }
    
    if (lowerText.includes('import') || lowerText.includes('export')) {
      return type === 'original'
        ? `import { oldMethod } from './old-module';`
        : `import { newMethod } from './improved-module';`;
    }
    
    if (lowerText.includes('async') || lowerText.includes('promise')) {
      return type === 'original'
        ? `function getData() {\n  return fetch('/api/data');\n}`
        : `async function getData() {\n  return await fetch('/api/data');\n}`;
    }
    
    // Default fallback
    return type === 'original'
      ? `// Original code implementation\n// ${text.slice(0, 50)}...`
      : `// Improved code implementation\n// ${text.slice(0, 50)}...`;
  }

  private buildFocusedCodePrompt(
    prTitle: string,
    prDescription: string,
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>,
    enhancedContext?: any
  ): string {
    const fileSummary = changedFiles.map(file => 
      `- ${file.filename}: +${file.additions} -${file.deletions}`
    ).join('\n');

    // Build enhanced context sections
    const contextSections = this.buildEnhancedContextSections(enhancedContext);
    
    // Measure context size
    const contextMetrics = this.measureContextSize(prTitle, prDescription, diff, fileSummary, contextSections);
    // Context metrics calculated

    return `You are a **senior software engineer** performing a **code review** on a GitHub Pull Request. 
Act like a highly experienced reviewer: focus on correctness, maintainability, performance, scalability, security, and best practices. 
Be strict but constructive, and provide actionable, detailed insights.

---
## PR Context
- **Title:** ${prTitle}
- **Description:** ${prDescription || 'No description provided'}
- **Changed Files:** ${fileSummary}  

${contextSections}

- **Diff:**  
\`\`\`diff
${diff}
\`\`\`
---

## Review Tasks
1. **Summarize Intent**  
   - Explain what this PR is trying to achieve in simple words.  

2. **Potential Issues**  
   - Detect possible **bugs, logic flaws, performance bottlenecks, and security vulnerabilities**.  
   - Flag risky patterns (e.g., N+1 queries, hardcoded secrets, race conditions, memory leaks).  

3. **Refactor Suggestions**  
   - Suggest **clear, practical improvements** (e.g., extract methods, reduce duplication, improve naming, follow SOLID/DRY/KISS).  
   - Include rationale for each suggestion.  

4. **Testing Recommendations**  
   - Identify **missing or weak test coverage**.  
   - Suggest **specific test cases** that should be added.  

5. **Best Practices**  
   - Point out violations of coding conventions, style, or architectural patterns.  
   - Recommend frameworks or library best practices (security headers, async handling, error management).  

6. **Final Review Verdict**  
   - State whether this PR is **safe to merge**, needs **minor changes**, or requires **major fixes**.  

---
## Output Format (Strict JSON)
Return the result in this JSON format:

{
  "summary": "<2-3 sentence high-level summary>",
  "potentialIssues": [
    { "file": "<filename>", "line": <line_number>, "issue": "<detailed issue description>", "severity": "low|medium|high" }
  ],
  "refactorSuggestions": [
    { "file": "<filename>", "line": <line_number>, "suggestion": "<actionable improvement>", "rationale": "<why>" }
  ],
  "testRecommendations": [
    { "file": "<filename>", "suggestion": "<missing test or edge case>" }
  ],
  "bestPractices": [
    { "file": "<filename>", "suggestion": "<improvement for maintainability or readability>" }
  ],
  "finalVerdict": "safe|minor_changes|major_fixes"
}`;
  }

  private buildEnhancedContextSections(enhancedContext?: any): string {
    if (!enhancedContext) return "";

    let contextSections = "";

    // 1. Repository History Context
    if (enhancedContext.recentCommits?.length > 0) {
      contextSections += `
## Repository History (Recent Changes)
${enhancedContext.recentCommits.map((fileCommits: any) => 
  `**${fileCommits.file}:**\n${fileCommits.recentCommits.map((commit: any) => 
    `  - ${commit.sha}: ${commit.message} (${commit.author})`
  ).join('\n')}`
).join('\n\n')}`;
    }

    // 2. Branch Context
    if (enhancedContext.branchContext) {
      const branch = enhancedContext.branchContext;
      contextSections += `
## Branch Context
- **Base Branch:** ${branch.baseBranch} → **Head Branch:** ${branch.headBranch}
- **Mergeable:** ${branch.mergeable ? '✅ Yes' : '❌ No'} (${branch.mergeableState})
- **Branch Status:** ${branch.aheadBy} commits ahead, ${branch.behindBy} commits behind
${branch.conflictFiles ? `- **⚠️ Conflicts:** ${branch.conflictFiles}` : ''}`;
    }

    // 3. Linked Issues Context
    if (enhancedContext.linkedIssues?.length > 0) {
      contextSections += `
## Linked Issues
${enhancedContext.linkedIssues.map((issue: any) => 
  `**Issue #${issue.number}** (${issue.state}): ${issue.title}\n${issue.body ? `Description: ${issue.body.substring(0, 200)}...` : ''}\nLabels: ${issue.labels.join(', ')}`
).join('\n\n')}`;
    }

    // 4. Repository Structure Context
    if (enhancedContext.repoStructure && Object.keys(enhancedContext.repoStructure).length > 0) {
      contextSections += `
## Repository Structure`;
      
      if (enhancedContext.repoStructure.dependencies) {
        const deps = enhancedContext.repoStructure.dependencies;
        contextSections += `
**Dependencies:** ${deps.dependencies.slice(0, 10).join(', ')}${deps.dependencies.length > 10 ? '...' : ''}
**Dev Dependencies:** ${deps.devDependencies.slice(0, 10).join(', ')}${deps.devDependencies.length > 10 ? '...' : ''}
**Scripts:** ${deps.scripts.join(', ')}`;
      }

      Object.keys(enhancedContext.repoStructure).forEach(configFile => {
        if (configFile !== 'dependencies') {
          contextSections += `
**${configFile}:** Configuration detected`;
        }
      });
    }

    // 5. CI/CD Context
    if (enhancedContext.cicdContext) {
      const ci = enhancedContext.cicdContext;
      contextSections += `
## CI/CD Status
- **Total Checks:** ${ci.summary.totalChecks}
- **✅ Passing:** ${ci.summary.passing} | **❌ Failing:** ${ci.summary.failing}
${ci.checkRuns.length > 0 ? `**Recent Checks:** ${ci.checkRuns.slice(0, 3).map((run: any) => `${run.name} (${run.conclusion})`).join(', ')}` : ''}`;
    }

    // 6. Review Comments Context
    if (enhancedContext.reviewComments?.reviews?.length > 0 || enhancedContext.reviewComments?.comments?.length > 0) {
      contextSections += `
## Existing Review Context`;
      
      if (enhancedContext.reviewComments.reviews.length > 0) {
        contextSections += `
**Previous Reviews:** ${enhancedContext.reviewComments.reviews.map((review: any) => 
          `${review.user} (${review.state}): ${review.body.substring(0, 100)}...`
        ).join(' | ')}`;
      }
      
      if (enhancedContext.reviewComments.comments.length > 0) {
        contextSections += `
**Review Comments:** ${enhancedContext.reviewComments.comments.length} existing comments on specific lines`;
      }
    }

    // 7. FULL FILE CONTEXT - Complete file content for better understanding
    if (enhancedContext.fullFileContext && Object.keys(enhancedContext.fullFileContext).length > 0) {
      contextSections += `
## 📄 Complete File Context (Full Codebase Access)`;
      
      Object.entries(enhancedContext.fullFileContext).forEach(([filename, fileData]: [string, any]) => {
        contextSections += `

### ${filename} (${fileData.lines} lines, ${fileData.size} chars)
\`\`\`${this.getFileExtension(filename)}
${fileData.content}
\`\`\``;
      });
    }

    // 8. RELATED CODE CONTEXT - Dependencies and related files
    if (enhancedContext.relatedCode) {
      const relatedCode = enhancedContext.relatedCode;
      
      if (Object.keys(relatedCode.imports || {}).length > 0 || 
          Object.keys(relatedCode.exports || {}).length > 0 ||
          relatedCode.testFiles?.length > 0 ||
          relatedCode.relatedFiles?.length > 0) {
        
        contextSections += `
## 🔗 Related Code & Dependencies`;

        // Show imports/exports
        if (Object.keys(relatedCode.imports || {}).length > 0) {
          contextSections += `
**Imports by File:**`;
          Object.entries(relatedCode.imports).forEach(([file, imports]: [string, any]) => {
            if (imports.length > 0) {
              contextSections += `
- **${file}:** ${imports.join(', ')}`;
            }
          });
        }

        if (Object.keys(relatedCode.exports || {}).length > 0) {
          contextSections += `
**Exports by File:**`;
          Object.entries(relatedCode.exports).forEach(([file, exports]: [string, any]) => {
            if (exports.length > 0) {
              contextSections += `
- **${file}:** ${exports.join(', ')}`;
            }
          });
        }

        // Show test files
        if (relatedCode.testFiles?.length > 0) {
          contextSections += `
**🧪 Related Test Files:** ${relatedCode.testFiles.join(', ')}`;
        }

        // Show related files with content preview
        if (relatedCode.relatedFiles?.length > 0) {
          contextSections += `
**📁 Related Files:**`;
          relatedCode.relatedFiles.forEach((file: any) => {
            if (file && file.path && file.content) {
              contextSections += `

### ${file.path} (preview)
\`\`\`${this.getFileExtension(file.path)}
${file.content}
\`\`\``;
            }
          });
        }
      }
    }

    // 9. ARCHITECTURAL CONTEXT - Project documentation and configuration
    if (enhancedContext.architecturalContext) {
      const archContext = enhancedContext.architecturalContext;
      
      if (Object.keys(archContext.documentation || {}).length > 0 ||
          Object.keys(archContext.configurations || {}).length > 0 ||
          archContext.projectStructure) {
        
        contextSections += `
## 🏗️ Architectural Context & Project Documentation`;

        // Documentation files
        if (Object.keys(archContext.documentation || {}).length > 0) {
          contextSections += `
**📚 Project Documentation:**`;
          Object.entries(archContext.documentation).forEach(([filename, fileData]: [string, any]) => {
            contextSections += `

### ${filename} (${(fileData.size/1000).toFixed(1)}KB)
\`\`\`markdown
${fileData.content}
\`\`\``;
          });
        }

        // Configuration files
        if (Object.keys(archContext.configurations || {}).length > 0) {
          contextSections += `
**⚙️ Project Configuration:**`;
          Object.entries(archContext.configurations).forEach(([filename, fileData]: [string, any]) => {
            const ext = this.getFileExtension(filename);
            contextSections += `

### ${filename} (${(fileData.size/1000).toFixed(1)}KB)
\`\`\`${ext}
${fileData.content}
\`\`\``;
          });
        }

        // Project structure
        if (archContext.projectStructure) {
          const structure = archContext.projectStructure;
          if (structure.rootFiles?.length > 0 || structure.rootDirectories?.length > 0) {
            contextSections += `
**📁 Project Structure:**`;
            
            if (structure.rootDirectories?.length > 0) {
              contextSections += `
- **Directories:** ${structure.rootDirectories.join(', ')}`;
            }
            
            if (structure.rootFiles?.length > 0) {
              contextSections += `
- **Root Files:** ${structure.rootFiles.join(', ')}`;
            }
          }
        }
      }
    }

    return contextSections;
  }

  private getFileExtension(filename: string): string {
    const ext = filename.split('.').pop()?.toLowerCase();
    const languageMap: { [key: string]: string } = {
      'js': 'javascript',
      'jsx': 'javascript',
      'ts': 'typescript',
      'tsx': 'typescript',
      'py': 'python',
      'java': 'java',
      'go': 'go',
      'rs': 'rust',
      'cpp': 'cpp',
      'c': 'c',
      'cs': 'csharp',
      'php': 'php',
      'rb': 'ruby',
      'swift': 'swift',
      'kt': 'kotlin'
    };
    return languageMap[ext || ''] || ext || '';
  }

  private measureContextSize(
    prTitle: string, 
    prDescription: string, 
    diff: string, 
    fileSummary: string, 
    contextSections: string
  ) {
    // Rough token estimation (1 token ≈ 4 characters)
    const estimateTokens = (text: string) => Math.ceil(text.length / 4);

    const metrics = {
      prTitle: {
        chars: prTitle.length,
        tokens: estimateTokens(prTitle)
      },
      prDescription: {
        chars: prDescription.length,
        tokens: estimateTokens(prDescription)
      },
      diff: {
        chars: diff.length,
        tokens: estimateTokens(diff),
        lines: diff.split('\n').length
      },
      fileSummary: {
        chars: fileSummary.length,
        tokens: estimateTokens(fileSummary)
      },
      enhancedContext: {
        chars: contextSections.length,
        tokens: estimateTokens(contextSections),
        sections: contextSections.split('##').length - 1
      },
      total: {
        chars: prTitle.length + prDescription.length + diff.length + fileSummary.length + contextSections.length,
        estimatedTokens: estimateTokens(prTitle + prDescription + diff + fileSummary + contextSections),
        geminiLimit: 1000000, // Gemini Pro context limit
        utilizationPercent: 0
      }
    };

    metrics.total.utilizationPercent = Math.round((metrics.total.estimatedTokens / metrics.total.geminiLimit) * 100 * 100) / 100;

    return metrics;
  }

  private parseCodeFocusedResponse(
    text: string, 
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>,
    diff?: string
  ): AIAnalysisResult {
    // Store diff for use in extraction methods
    this.currentDiff = diff;
    try {
      // Clean and parse the response
      const cleanedResponse = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      const parsed = JSON.parse(cleanedResponse);
      
      // Convert the new format to our existing structure
      const codeSuggestions = [
        // Convert refactor suggestions
        ...(parsed.refactorSuggestions || []).map((item: any) => ({
          file: item.file,
          line: item.line || 1,
          original: this.extractOriginalCodeFromSuggestion(item, this.currentDiff),
          suggested: this.extractSuggestedCodeFromSuggestion(item, this.currentDiff),
          reason: item.rationale || item.suggestion,
          severity: "MEDIUM" as const,
          category: "Refactoring" as const
        })),
        // Convert potential issues
        ...(parsed.potentialIssues || []).map((item: any) => ({
          file: item.file,
          line: item.line || 1,
          original: this.extractOriginalCodeFromIssue(item),
          suggested: this.extractSuggestedCodeFromIssue(item),
          reason: item.issue,
          severity: item.severity?.toUpperCase() || "MEDIUM" as const,
          category: "Logic" as const
        })),
        // Convert best practices
        ...(parsed.bestPractices || []).map((item: any) => ({
          file: item.file,
          line: 1,
          original: this.extractOriginalCodeFromBestPractice(item),
          suggested: this.extractSuggestedCodeFromBestPractice(item),
          reason: item.suggestion,
          severity: "LOW" as const,
          category: "Style" as const
        }))
      ];

      // Format suggestions and issues as text
      const refactorText = (parsed.refactorSuggestions || [])
        .map((item: any) => `**${item.file} (MEDIUM):** ${item.suggestion}\n- ${item.rationale}`)
        .join('\n\n');

      const issuesText = (parsed.potentialIssues || [])
        .map((item: any) => `**${item.file} (${item.severity?.toUpperCase() || 'MEDIUM'}):** ${item.issue}`)
        .join('\n\n');

      return {
        summary: parsed.summary || "Code analysis completed",
        refactorSuggestions: refactorText || "No refactoring suggestions",
        potentialIssues: issuesText || "No critical issues found",
        detailedAnalysis: {
          overview: `${parsed.summary || "Analysis overview"} | Final Verdict: ${parsed.finalVerdict || 'review_required'}`,
          codeSuggestions,
          securityConcerns: (parsed.potentialIssues || [])
            .filter((item: any) => item.issue?.toLowerCase().includes('security') || item.severity === 'high')
            .map((item: any) => `${item.file}: ${item.issue}`),
          performanceImpact: (parsed.potentialIssues || [])
            .filter((item: any) => item.issue?.toLowerCase().includes('performance'))
            .map((item: any) => item.issue)
            .join('. ') || "No specific performance issues identified",
          testingRecommendations: (parsed.testRecommendations || [])
            .map((item: any) => `${item.file}: ${item.suggestion}`),
          architecturalNotes: (parsed.bestPractices || [])
            .map((item: any) => `${item.file}: ${item.suggestion}`)
        }
      };
    } catch (error) {
      // Simple fallback that ensures deep analysis works
      const fallback = this.parseAIResponse(text);
      return {
        ...fallback,
        detailedAnalysis: fallback.detailedAnalysis || {
          overview: fallback.summary,
          codeSuggestions: [
            {
              file: changedFiles[0]?.filename || "main changes",
              line: 1,
              original: "// Code changes detected",
              suggested: "// Review these changes for improvements",
              reason: "Manual code review recommended for these changes",
              severity: "MEDIUM" as const,
              category: "Review" as const
            }
          ],
          securityConcerns: ["Review code for security implications"],
          performanceImpact: "Monitor performance after deployment",
          testingRecommendations: ["Add tests for new functionality"],
          architecturalNotes: ["Review code structure and patterns"]
        }
      };
    }
  }

  private async runEnhancedAnalysis(
    prTitle: string,
    prDescription: string,
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>
  ): Promise<AIAnalysisResult & { multiPassAnalysis: MultiPassAnalysisResult }> {
    // Starting enhanced single-pass analysis

    const fileSummary = changedFiles.map(file => 
      `- ${file.filename}: +${file.additions} -${file.deletions} (${file.changes} changes)`
    ).join('\n');

    const totalChanges = changedFiles.reduce((sum, file) => sum + file.changes, 0);
    const fileCount = changedFiles.length;

    const enhancedPrompt = `You are a **SENIOR SOFTWARE ARCHITECT** conducting a comprehensive multi-dimensional code review.

**CRITICAL INSTRUCTION**: You MUST provide a complete multi-pass analysis in a SINGLE response. Think like you're doing 4 different review passes:

1. **HIGH-LEVEL OVERVIEW** (Strategic View)
2. **FILE-BY-FILE ANALYSIS** (Detailed Implementation)  
3. **CROSS-FILE CONSISTENCY** (Integration & Architecture)
4. **PRIORITIZED RECOMMENDATIONS** (Action Items)

PR CONTEXT:
Title: ${prTitle}
Description: ${prDescription || 'No description provided'}

FILES CHANGED (${fileCount} files, ${totalChanges} total changes):
${fileSummary}

REPOSITORY CONTEXT:
- Language: ${this.detectPrimaryLanguage(changedFiles)}
- Framework: ${this.detectFramework(changedFiles)}
- File Types: ${this.getFileTypes(changedFiles)}

COMPLETE DIFF FOR ANALYSIS:
\`\`\`diff
${diff}
\`\`\`

**RESPONSE FORMAT**: You MUST respond with ONLY valid JSON in this EXACT structure:

{
  "summary": "Brief overall summary of what this PR accomplishes",
  "refactorSuggestions": "Formatted refactoring suggestions with examples",
  "potentialIssues": "Critical issues and problems identified",
  "detailedAnalysis": {
    "overview": "Comprehensive technical overview",
    "codeSuggestions": [
      {
        "file": "filename",
        "line": 42,
        "original": "current code snippet",
        "suggested": "improved code snippet", 
        "reason": "detailed explanation",
        "severity": "HIGH|MEDIUM|LOW",
        "category": "Security|Performance|Logic|Architecture"
      }
    ],
    "securityConcerns": ["Security analysis points"],
    "performanceImpact": "Performance implications analysis",
    "testingRecommendations": ["Testing suggestions"],
    "architecturalNotes": ["Architecture observations"]
  },
  "multiPassAnalysis": {
    "overallSummary": "What this PR accomplishes strategically",
    "impactAssessment": "System areas affected and impact analysis", 
    "changeComplexity": "LOW|MEDIUM|HIGH",
    "fileAnalyses": [
      {
        "filename": "path/to/file",
        "summary": "What changed in this file",
        "issues": [/* CodeSuggestion objects for this file */],
        "complexity": "LOW|MEDIUM|HIGH",
        "riskLevel": "LOW|MEDIUM|HIGH", 
        "dependencies": ["related files/modules"]
      }
    ],
    "crossFileAnalysis": {
      "consistencyIssues": ["Cross-file consistency problems"],
      "dependencyConflicts": ["Dependency-related issues"],
      "architecturalConcerns": ["Architecture violations"],
      "integrationRisks": ["Integration risks between files"]
    },
    "prioritizedIssues": [/* All issues sorted by severity */],
    "riskAssessment": "Overall risk analysis",
    "recommendedActions": ["Prioritized action items"]
  }
}

**ANALYSIS REQUIREMENTS**:

🔍 **PASS 1 - STRATEGIC OVERVIEW**: 
- What business/technical problem does this solve?
- What systems/components are affected?
- Assess change complexity and risk level

📁 **PASS 2 - FILE-BY-FILE DEEP DIVE**:
- Analyze each file's changes individually
- Identify specific code issues, improvements
- Assess complexity and risk per file
- Map dependencies and relationships

🔗 **PASS 3 - CROSS-FILE INTEGRATION**:
- Check consistency across files (naming, patterns, styles)
- Identify dependency conflicts or circular dependencies  
- Look for architectural violations
- Assess integration risks

🎯 **PASS 4 - PRIORITIZED RECOMMENDATIONS**:
- Rank ALL issues by severity (HIGH → MEDIUM → LOW)
- Provide overall risk assessment
- Give specific, actionable next steps

**FOCUS AREAS**:
- **Security**: SQL injection, XSS, authentication, authorization
- **Performance**: N+1 queries, memory leaks, inefficient algorithms
- **Logic**: Edge cases, error handling, business logic flaws  
- **Architecture**: SOLID principles, design patterns, coupling
- **Maintainability**: Code duplication, complexity, readability

Be thorough but practical. Provide specific code examples and actionable insights.`;

    const result = await this.model.generateContent(enhancedPrompt);
    const response = await result.response;
    const text = response.text();

    try {
      const cleanedResponse = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      const parsedResult = JSON.parse(cleanedResponse);
      
      // Enhanced analysis completed successfully
      return parsedResult;
    } catch (error) {
      // Enhanced analysis JSON parsing failed, using enhanced fallback
      
      // Enhanced fallback that still provides rich analysis
      const fallbackResult = this.parseAIResponse(text);
      
      // Create a proper detailedAnalysis if it doesn't exist
      const detailedAnalysis = fallbackResult.detailedAnalysis || {
        overview: `Enhanced analysis of ${fileCount} files with ${totalChanges} total changes. This PR introduces significant functionality with potential architectural implications.`,
        codeSuggestions: [
          {
            file: changedFiles[0]?.filename || "multiple files",
            line: 1,
            original: "// Complex changes detected",
            suggested: "// Consider breaking down complex changes into smaller, focused commits",
            reason: "Large PRs with many changes can be difficult to review and test thoroughly. Consider splitting into smaller, logical units.",
            severity: "MEDIUM" as const,
            category: "Architecture" as const
          }
        ],
        securityConcerns: [
          "Large PR with multiple file changes - ensure all security implications are reviewed",
          "Authentication and data handling changes require careful security review"
        ],
        performanceImpact: `This PR modifies ${fileCount} files which may have performance implications. Monitor for any performance regressions after deployment.`,
        testingRecommendations: [
          "Comprehensive testing required due to scope of changes",
          "Integration testing recommended for new features",
          "Performance testing for user-facing changes"
        ],
        architecturalNotes: [
          `Large-scale changes across ${fileCount} files suggest significant architectural modifications`,
          "Consider documentation updates to reflect new architecture",
          "Review consistency of patterns across modified files"
        ]
      };

      return {
        summary: fallbackResult.summary,
        refactorSuggestions: fallbackResult.refactorSuggestions,
        potentialIssues: fallbackResult.potentialIssues,
        detailedAnalysis: detailedAnalysis,
        multiPassAnalysis: {
          summary: fallbackResult.summary,
          refactorSuggestions: fallbackResult.refactorSuggestions,
          potentialIssues: fallbackResult.potentialIssues,
          overallSummary: fallbackResult.summary,
          impactAssessment: `Comprehensive analysis of ${fileCount} files with ${totalChanges} changes. This represents a significant update with potential impacts on architecture, security, and performance.`,
          changeComplexity: totalChanges > 500 ? 'HIGH' as const : totalChanges > 100 ? 'MEDIUM' as const : 'LOW' as const,
          fileAnalyses: changedFiles.map(file => ({
            filename: file.filename,
            summary: `Modified ${file.filename} with ${file.changes} changes - complexity assessment based on change volume`,
            issues: file.changes > 50 ? [{
              file: file.filename,
              line: 1,
            original: "// Large number of changes detected",
            suggested: "// Consider reviewing this file carefully due to extensive modifications",
              reason: `This file has ${file.changes} changes which may indicate complex modifications requiring thorough review`,
              severity: "MEDIUM" as const,
              category: "Maintainability" as const
            }] : [],
            complexity: file.changes > 50 ? 'HIGH' as const : file.changes > 20 ? 'MEDIUM' as const : 'LOW' as const,
            riskLevel: file.changes > 100 ? 'HIGH' as const : file.changes > 30 ? 'MEDIUM' as const : 'LOW' as const,
            dependencies: []
          })),
          crossFileAnalysis: {
            consistencyIssues: fileCount > 10 ? ["Large number of files modified - ensure consistent patterns and naming conventions"] : [],
            dependencyConflicts: [],
            architecturalConcerns: totalChanges > 300 ? ["Significant architectural changes detected - review for consistency with existing patterns"] : [],
            integrationRisks: ["Multiple file changes may require integration testing", "Ensure compatibility between modified components"]
          },
          prioritizedIssues: detailedAnalysis.codeSuggestions,
          riskAssessment: `${totalChanges > 500 ? 'HIGH' : totalChanges > 100 ? 'MEDIUM' : 'LOW'} risk assessment based on scope: ${fileCount} files modified with ${totalChanges} total changes. Enhanced analysis provides comprehensive insights despite JSON parsing challenges.`,
          recommendedActions: [
            'Review high-complexity files first',
            'Run comprehensive testing suite',
            'Monitor for performance impacts post-deployment',
            'Update documentation if architectural changes are present'
          ]
        }
      };
    }
  }

  private async runMultiPassAnalysis(
    prTitle: string,
    prDescription: string,
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>
  ): Promise<MultiPassAnalysisResult> {
    // Starting multi-pass analysis

    // Pass 1: High-level overview and impact assessment
    const pass1Result = await this.runPass1Analysis(prTitle, prDescription, changedFiles);

    // Pass 2: File-by-file detailed analysis
    const pass2Result = await this.runPass2Analysis(diff, changedFiles);

    // Pass 3: Cross-file consistency and dependency analysis
    const pass3Result = await this.runPass3Analysis(pass2Result, diff);

    // Pass 4: Final prioritization and categorization
    const pass4Result = await this.runPass4Analysis(pass1Result, pass2Result, pass3Result);

    // Multi-pass analysis complete

    return {
      // Pass 1 results
      overallSummary: pass1Result.overallSummary,
      impactAssessment: pass1Result.impactAssessment,
      changeComplexity: pass1Result.changeComplexity,

      // Pass 2 results
      fileAnalyses: pass2Result,

      // Pass 3 results
      crossFileAnalysis: pass3Result,

      // Pass 4 results
      prioritizedIssues: pass4Result.prioritizedIssues,
      riskAssessment: pass4Result.riskAssessment,
      recommendedActions: pass4Result.recommendedActions,

      // Legacy compatibility
      summary: pass1Result.overallSummary,
      refactorSuggestions: pass4Result.recommendedActions.join('\n\n'),
      potentialIssues: pass3Result.consistencyIssues.concat(pass3Result.dependencyConflicts).join('\n\n'),
      detailedAnalysis: {
        overview: pass1Result.overallSummary,
        codeSuggestions: pass4Result.prioritizedIssues,
        securityConcerns: pass4Result.prioritizedIssues
          .filter(issue => issue.category.toLowerCase().includes('security'))
          .map(issue => `${issue.file}: ${issue.reason}`),
        performanceImpact: pass1Result.impactAssessment,
        testingRecommendations: pass4Result.recommendedActions
          .filter(action => action.toLowerCase().includes('test')),
        architecturalNotes: pass3Result.architecturalConcerns
      }
    };
  }

  private buildAnalysisPrompt(
    prTitle: string,
    prDescription: string,
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>
  ): string {
    const fileSummary = changedFiles.map(file => 
      `- ${file.filename}: +${file.additions} -${file.deletions} (${file.changes} total changes)`
    ).join('\n');

    return `You are a **senior software engineer** performing a **code review** on a GitHub Pull Request. 
Act like a highly experienced reviewer with 10+ years of experience: focus on correctness, maintainability, performance, scalability, security, and best practices.
Be strict but constructive, and provide actionable, detailed insights like CodeRabbit or senior developers.

**Think like a mentor reviewer, not a linter.** Look for:
- Logic flaws and potential bugs
- Performance bottlenecks (N+1 queries, memory leaks, inefficient algorithms)
- Security vulnerabilities (SQL injection, XSS, authentication issues)
- Architecture improvements (SOLID principles, design patterns)
- Missing error handling and edge cases
- Code duplication and refactoring opportunities

CRITICAL: You MUST respond with ONLY valid JSON. Do not include any text before or after the JSON. Do not wrap the JSON in markdown code blocks.

Your response must be a valid JSON object with the following structure:

{
  "summary": "A concise, professional summary of what this PR accomplishes",
  "refactorSuggestions": "Specific refactoring suggestions with code examples. Format each suggestion as:\\n**Category (SEVERITY):** Description\\n- Specific issue explanation\\n- Show original code snippet if relevant\\n- Provide improved code example\\n- Explain the benefits of the change",
  "potentialIssues": "Critical analysis of potential problems. Format each issue as:\\n**Issue Name (SEVERITY):** Description\\n- Detailed explanation of the problem\\n- Show problematic code if applicable\\n- Potential impact and consequences\\n- Recommended fixes with code examples",
  "detailedAnalysis": {
    "overview": "Comprehensive technical overview of the changes",
    "codeSuggestions": [
      {
        "file": "filename",
        "line": 42,
        "original": "// MUST be actual code, not plain text comments\nconst originalCode = 'example';",
        "suggested": "// MUST be actual code, not plain text comments\nconst improvedCode = 'better example';",
        "reason": "detailed explanation of why this improvement is needed",
        "severity": "HIGH",
        "category": "Performance"
      }
    ],
    "securityConcerns": ["Detailed security analysis points"],
    "performanceImpact": "Analysis of performance implications",
    "testingRecommendations": ["Specific testing suggestions"],
    "architecturalNotes": ["Architectural and design pattern observations"]
  }
}

ANALYSIS REQUIREMENTS:
1. **Code-Level Review**: Examine actual code changes line by line
2. **Concrete Examples**: Provide specific code snippets from the diff
3. **Before/After Suggestions**: Show original code and improved versions
4. **Technical Depth**: Include architectural, security, and performance analysis
5. **Actionable Feedback**: Each suggestion should be implementable
6. **Severity Assessment**: Properly categorize issues by importance
7. **Best Practices**: Reference industry standards and patterns

🚀 MAXIMUM CONTEXT AVAILABLE - YOU HAVE UNPRECEDENTED ACCESS:
- ✅ COMPLETE FILE CONTENT (up to 1MB per file, 25 files total)
- ✅ FULL DEPENDENCY GRAPH (imports, exports, related files with 5KB previews)
- ✅ ALL TEST FILES (automatically discovered and included)
- ✅ PROJECT ARCHITECTURE (README, docs, configs, project structure)
- ✅ COMPREHENSIVE CODEBASE UNDERSTANDING (not just diff snippets)

CRITICAL CODE REQUIREMENTS:
- You have MAXIMUM CONTEXT - use it to provide the most intelligent suggestions possible
- The "original" field MUST contain actual code from the complete files with full context
- The "suggested" field MUST contain production-ready code that fits the project's patterns
- Analyze the entire codebase context: architecture, dependencies, tests, documentation
- Consider project-specific patterns from configs (ESLint, TypeScript, framework configs)
- Reference documentation and architectural decisions in your reasoning
- Show comprehensive before/after code with 10-15 lines of context
- Ensure suggestions align with the project's coding standards and architectural patterns
- Provide enterprise-grade suggestions that consider the full system impact

PR CONTEXT:
Title: ${prTitle}
Description: ${prDescription || 'No description provided'}

Files Changed:
${fileSummary}

REPOSITORY CONTEXT:
- Language: ${this.detectPrimaryLanguage(changedFiles)}
- Framework: ${this.detectFramework(changedFiles)}
- File Types: ${this.getFileTypes(changedFiles)}

COMPLETE DIFF FOR ANALYSIS:
\`\`\`diff
${diff}
\`\`\`

INSTRUCTIONS:
- Analyze EVERY significant code change in the diff
- Look for patterns across multiple files
- Consider the broader impact of changes
- Identify opportunities for improvement beyond just fixing bugs
- Be specific about file names, line numbers, and code snippets
- Provide practical, implementable suggestions
- Consider security, performance, maintainability, and correctness
- If you see good practices, mention them as positive feedback`;
  }

  private parseAIResponse(response: string): AIAnalysisResult {
    try {
      // Clean the response - remove any markdown code blocks
      let cleanedResponse = response;
      
      // Remove markdown code blocks if present
      cleanedResponse = cleanedResponse.replace(/```json\s*/gi, '');
      cleanedResponse = cleanedResponse.replace(/```\s*/g, '');
      
      // Try multiple JSON extraction methods
      let jsonMatch = cleanedResponse.match(/\{[\s\S]*\}/);
      
      if (!jsonMatch) {
        // Try to find JSON starting with { and ending with }
        const startIndex = cleanedResponse.indexOf('{');
        const lastIndex = cleanedResponse.lastIndexOf('}');
        
        if (startIndex !== -1 && lastIndex !== -1 && lastIndex > startIndex) {
          jsonMatch = [cleanedResponse.substring(startIndex, lastIndex + 1)];
        }
      }

      if (!jsonMatch) {
        console.error("No JSON found in AI response after cleaning");
        throw new Error("No JSON found in AI response");
      }

      const parsed = JSON.parse(jsonMatch[0]);
      
      return {
        summary: parsed.summary || "Analysis completed",
        refactorSuggestions: parsed.refactorSuggestions || "No refactoring suggestions provided",
        potentialIssues: parsed.potentialIssues || "No potential issues identified",
        detailedAnalysis: parsed.detailedAnalysis ? {
          overview: parsed.detailedAnalysis.overview || "",
          codeSuggestions: Array.isArray(parsed.detailedAnalysis.codeSuggestions) ? parsed.detailedAnalysis.codeSuggestions : [],
          securityConcerns: Array.isArray(parsed.detailedAnalysis.securityConcerns) ? parsed.detailedAnalysis.securityConcerns : [],
          performanceImpact: parsed.detailedAnalysis.performanceImpact || "",
          testingRecommendations: Array.isArray(parsed.detailedAnalysis.testingRecommendations) ? parsed.detailedAnalysis.testingRecommendations : [],
          architecturalNotes: Array.isArray(parsed.detailedAnalysis.architecturalNotes) ? parsed.detailedAnalysis.architecturalNotes : []
        } : undefined
      };
    } catch (error) {
      console.error("Error parsing AI response:", error);
      console.error("Response length:", response.length);
      console.error("First 500 chars:", response.substring(0, 500));
      
      // Enhanced fallback parsing - try to extract basic info
      const summaryMatch = response.match(/"summary":\s*"([^"]*?)"/);
      const refactorMatch = response.match(/"refactorSuggestions":\s*"([\s\S]*?)"/);
      const issuesMatch = response.match(/"potentialIssues":\s*"([\s\S]*?)"/);
      
      return {
        summary: summaryMatch ? summaryMatch[1] : "AI analysis completed - parsing error occurred",
        refactorSuggestions: refactorMatch ? refactorMatch[1] : "Analysis completed but response parsing failed. Raw response logged to server.",
        potentialIssues: issuesMatch ? issuesMatch[1] : "Analysis completed but response parsing failed. Raw response logged to server."
      };
    }
  }

  // Pass 1: High-level overview and impact assessment
  private async runPass1Analysis(
    prTitle: string,
    prDescription: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>
  ): Promise<{ overallSummary: string; impactAssessment: string; changeComplexity: 'LOW' | 'MEDIUM' | 'HIGH' }> {
    const fileSummary = changedFiles.map(file => 
      `- ${file.filename}: +${file.additions} -${file.deletions} (${file.changes} changes)`
    ).join('\n');

    const totalChanges = changedFiles.reduce((sum, file) => sum + file.changes, 0);
    const fileCount = changedFiles.length;

    const prompt = `You are conducting PASS 1 of a multi-pass code review: HIGH-LEVEL OVERVIEW & IMPACT ASSESSMENT.

Focus ONLY on the big picture - don't get into specific code details yet.

PR TITLE: ${prTitle}
DESCRIPTION: ${prDescription || 'No description provided'}

FILES CHANGED (${fileCount} files, ${totalChanges} total changes):
${fileSummary}

REPOSITORY CONTEXT:
- Primary Language: ${this.detectPrimaryLanguage(changedFiles)}
- Framework: ${this.detectFramework(changedFiles)}
- File Types: ${this.getFileTypes(changedFiles)}

PASS 1 ANALYSIS REQUIREMENTS:
1. **Overall Summary**: What does this PR accomplish? (2-3 sentences)
2. **Impact Assessment**: What areas of the system are affected? Performance, security, UX, etc.
3. **Change Complexity**: LOW/MEDIUM/HIGH based on scope and risk

Respond with ONLY valid JSON:
{
  "overallSummary": "Brief description of what this PR does",
  "impactAssessment": "Analysis of system impact and affected areas",
  "changeComplexity": "LOW" | "MEDIUM" | "HIGH"
}`;

    const result = await this.model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    try {
      const cleanedResponse = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      return JSON.parse(cleanedResponse);
    } catch {
      // Pass 1 JSON parsing failed, using fallback
      return {
        overallSummary: `This PR modifies ${fileCount} files with ${totalChanges} total changes`,
        impactAssessment: 'Impact analysis failed - manual review recommended',
        changeComplexity: totalChanges > 500 ? 'HIGH' : totalChanges > 100 ? 'MEDIUM' : 'LOW'
      };
    }
  }

  // Pass 2: File-by-file detailed analysis
  private async runPass2Analysis(
    diff: string,
    changedFiles: Array<{ filename: string; additions: number; deletions: number; changes: number }>
  ): Promise<FileAnalysis[]> {
    // For large PRs, analyze files in batches to avoid token limits
    const maxFilesPerBatch = 5;
    const fileAnalyses: FileAnalysis[] = [];

    for (let i = 0; i < changedFiles.length; i += maxFilesPerBatch) {
      const batch = changedFiles.slice(i, i + maxFilesPerBatch);
      const batchAnalyses = await this.analyzeFileBatch(diff, batch);
      fileAnalyses.push(...batchAnalyses);
    }

    return fileAnalyses;
  }

  private async analyzeFileBatch(
    diff: string,
    files: Array<{ filename: string; additions: number; deletions: number; changes: number }>
  ): Promise<FileAnalysis[]> {
    const fileList = files.map(f => f.filename).join(', ');
    
    const prompt = `You are conducting PASS 2 of a multi-pass code review: FILE-BY-FILE DETAILED ANALYSIS.

Analyze each file individually for specific issues, complexity, and dependencies.

FILES TO ANALYZE: ${fileList}

COMPLETE DIFF:
\`\`\`diff
${diff}
\`\`\`

For each file, provide detailed analysis focusing on:
1. **File Summary**: What changes were made to this specific file
2. **Issues**: Specific code problems, bugs, or improvements needed
3. **Complexity**: How complex are the changes in this file (LOW/MEDIUM/HIGH)
4. **Risk Level**: How risky are these changes (LOW/MEDIUM/HIGH)
5. **Dependencies**: What other files/modules does this file depend on or affect

Respond with ONLY valid JSON array:
[
  {
    "filename": "path/to/file.js",
    "summary": "Description of changes in this file",
    "issues": [
      {
        "file": "path/to/file.js",
        "line": 42,
        "original": "problematic code",
        "suggested": "improved code",
        "reason": "why this improvement is needed",
        "severity": "HIGH|MEDIUM|LOW",
        "category": "Performance|Security|Logic|Style"
      }
    ],
    "complexity": "LOW|MEDIUM|HIGH",
    "riskLevel": "LOW|MEDIUM|HIGH",
    "dependencies": ["file1.js", "module2"]
  }
]`;

    const result = await this.model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    try {
      const cleanedResponse = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      return JSON.parse(cleanedResponse);
    } catch {
      // Pass 2 JSON parsing failed, using fallback
      return files.map(file => ({
        filename: file.filename,
        summary: `File analysis failed for ${file.filename}`,
        issues: [],
        complexity: file.changes > 50 ? 'HIGH' : file.changes > 20 ? 'MEDIUM' : 'LOW' as const,
        riskLevel: 'MEDIUM' as const,
        dependencies: []
      }));
    }
  }

  // Pass 3: Cross-file consistency and dependency analysis
  private async runPass3Analysis(
    fileAnalyses: FileAnalysis[],
    diff: string
  ): Promise<CrossFileAnalysis> {
    const filenames = fileAnalyses.map(f => f.filename);

    const prompt = `You are conducting PASS 3 of a multi-pass code review: CROSS-FILE CONSISTENCY & DEPENDENCY ANALYSIS.

Look for issues that span multiple files, inconsistencies, and dependency problems.

FILES ANALYZED: ${filenames.join(', ')}

FILE ANALYSES FROM PASS 2:
${JSON.stringify(fileAnalyses, null, 2)}

COMPLETE DIFF FOR CONTEXT:
\`\`\`diff
${diff}
\`\`\`

Analyze for:
1. **Consistency Issues**: Naming conventions, patterns, styles across files
2. **Dependency Conflicts**: Import/export issues, circular dependencies, missing dependencies
3. **Architectural Concerns**: Violations of patterns, coupling issues, separation of concerns
4. **Integration Risks**: How changes in one file might break functionality in others

Respond with ONLY valid JSON:
{
  "consistencyIssues": ["List of consistency problems across files"],
  "dependencyConflicts": ["List of dependency-related issues"],
  "architecturalConcerns": ["List of architectural problems"],
  "integrationRisks": ["List of integration risks between files"]
}`;

    const result = await this.model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    try {
      const cleanedResponse = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      return JSON.parse(cleanedResponse);
    } catch {
      // Pass 3 JSON parsing failed, using fallback
      return {
        consistencyIssues: [],
        dependencyConflicts: [],
        architecturalConcerns: [],
        integrationRisks: []
      };
    }
  }

  // Pass 4: Final prioritization and categorization
  private async runPass4Analysis(
    pass1Result: { overallSummary: string; impactAssessment: string; changeComplexity: 'LOW' | 'MEDIUM' | 'HIGH' },
    pass2Result: FileAnalysis[],
    pass3Result: CrossFileAnalysis
  ): Promise<{ prioritizedIssues: CodeSuggestion[]; riskAssessment: string; recommendedActions: string[] }> {
    const allIssues = pass2Result.flatMap(file => file.issues);

    const prompt = `You are conducting PASS 4 of a multi-pass code review: FINAL PRIORITIZATION & CATEGORIZATION.

Synthesize all previous analysis passes to provide final recommendations.

PASS 1 RESULTS (High-level):
${JSON.stringify(pass1Result, null, 2)}

PASS 2 RESULTS (File-by-file issues - ${allIssues.length} total):
${JSON.stringify(allIssues, null, 2)}

PASS 3 RESULTS (Cross-file analysis):
${JSON.stringify(pass3Result, null, 2)}

Your task:
1. **Prioritize Issues**: Rank all issues by importance (HIGH severity issues first)
2. **Risk Assessment**: Overall risk level and key concerns
3. **Recommended Actions**: Specific next steps for the developer

Respond with ONLY valid JSON:
{
  "prioritizedIssues": [
    {
      "file": "filename",
      "line": 42,
      "original": "code snippet",
      "suggested": "improved code",
      "reason": "detailed explanation",
      "severity": "HIGH|MEDIUM|LOW",
      "category": "Security|Performance|Logic|Architecture|Style"
    }
  ],
  "riskAssessment": "Overall risk analysis and key concerns",
  "recommendedActions": [
    "Specific action items for the developer to address"
  ]
}`;

    const result = await this.model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    try {
      const cleanedResponse = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      return JSON.parse(cleanedResponse);
    } catch {
      // Pass 4 JSON parsing failed, using fallback
      return {
        prioritizedIssues: allIssues.sort((a, b) => {
          const severityOrder = { HIGH: 3, MEDIUM: 2, LOW: 1 };
          return severityOrder[b.severity] - severityOrder[a.severity];
        }),
        riskAssessment: `Analysis of ${allIssues.length} issues across ${pass2Result.length} files with ${pass1Result.changeComplexity} complexity`,
        recommendedActions: ['Review and address high-severity issues first', 'Test thoroughly before merging']
      };
    }
  }

  private detectPrimaryLanguage(files: Array<{ filename: string }>): string {
    try {
      if (!files || files.length === 0) return 'Unknown';
      
      const extensions = files.map(f => f.filename?.split('.').pop()?.toLowerCase()).filter(Boolean);
      if (extensions.length === 0) return 'Mixed';
      
      const langMap: Record<string, string> = {
        'ts': 'TypeScript', 'tsx': 'TypeScript React',
        'js': 'JavaScript', 'jsx': 'JavaScript React',
        'py': 'Python', 'java': 'Java', 'go': 'Go',
        'rs': 'Rust', 'php': 'PHP', 'rb': 'Ruby',
        'swift': 'Swift', 'kt': 'Kotlin', 'dart': 'Dart'
      };
      
      const counts = extensions.reduce((acc, ext) => {
        if (ext) acc[ext] = (acc[ext] || 0) + 1;
        return acc;
      }, {} as Record<string, number>);
      
      const primaryExt = Object.entries(counts).sort(([,a], [,b]) => b - a)[0]?.[0];
      return langMap[primaryExt] || primaryExt || 'Mixed';
    } catch (error) {
      // Error detecting primary language
      return 'Unknown';
    }
  }

  private detectFramework(files: Array<{ filename: string }>): string {
    try {
      if (!files || files.length === 0) return 'Unknown';
      
      const filenames = files.map(f => f.filename?.toLowerCase()).filter(Boolean);
      if (filenames.length === 0) return 'Unknown';
      
      if (filenames.some(f => f.includes('package.json') || f.includes('node_modules'))) {
        if (filenames.some(f => f.includes('next') || f.includes('_app'))) return 'Next.js';
        if (filenames.some(f => f.includes('react') || f.endsWith('.tsx') || f.endsWith('.jsx'))) return 'React';
        if (filenames.some(f => f.includes('vue'))) return 'Vue.js';
        if (filenames.some(f => f.includes('angular'))) return 'Angular';
        return 'Node.js';
      }
      
      if (filenames.some(f => f.includes('requirements.txt') || f.includes('pyproject.toml'))) {
        if (filenames.some(f => f.includes('django'))) return 'Django';
        if (filenames.some(f => f.includes('flask'))) return 'Flask';
        if (filenames.some(f => f.includes('fastapi'))) return 'FastAPI';
        return 'Python';
      }
      
      return 'Unknown';
    } catch (error) {
      // Error detecting framework
      return 'Unknown';
    }
  }

  private getFileTypes(files: Array<{ filename: string }>): string {
    try {
      if (!files || files.length === 0) return 'Unknown';
      
      const types = new Set(files.map(f => {
        if (!f.filename) return 'Unknown';
        const name = f.filename.toLowerCase();
        if (name.includes('test') || name.includes('spec')) return 'Tests';
        if (name.includes('config') || name.includes('.json') || name.includes('.yml')) return 'Config';
        if (name.includes('component') || name.includes('page')) return 'UI Components';
        if (name.includes('api') || name.includes('route') || name.includes('controller')) return 'API/Backend';
        if (name.includes('util') || name.includes('helper')) return 'Utilities';
        if (name.includes('type') || name.includes('interface')) return 'Types';
        return 'Source Code';
      }));
      
      return Array.from(types).join(', ');
    } catch (error) {
      // Error detecting file types
      return 'Mixed';
    }
  }
}
